{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSn22IChf+BbzRFGQPShca",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyanta012/demo/blob/main/plam2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQEdAcuhWOhU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install google-cloud-aiplatform\n",
        "!pip uninstall shapely -y\n",
        "!pip install 'shapely<2.0.0'\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ランタイムの再起動が必要"
      ],
      "metadata": {
        "id": "oazWgNibqFZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"\""
      ],
      "metadata": {
        "id": "jRVDuNqYg4d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "MCn2vQEqX5TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import VertexAI\n",
        "import vertexai"
      ],
      "metadata": {
        "id": "cWxLeGK48xI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
      ],
      "metadata": {
        "id": "T-12--n6oTph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response_palm2(prompt):\n",
        "  params = {\n",
        "          \"max_output_tokens\": 512,\n",
        "          \"temperature\": 0,\n",
        "          \"top_p\": 0.5,\n",
        "          \"top_k\": 1\n",
        "      }\n",
        "  llm = VertexAI(model_name='text-bison-32k', **params)\n",
        "  question = f\"\"\"\n",
        "  {prompt}\n",
        "  \"\"\"\n",
        "  return llm(question)"
      ],
      "metadata": {
        "id": "kmwuuyxkpxf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_response_palm2(\"\"\"\n",
        "次の文章を日本語に翻訳してください\n",
        "\n",
        "QLORA (Dettmers et al., 2023) includes optimal\n",
        "quantization and memory optimization, aiming\n",
        "at providing efficient and effective LLMs finetuning. QLORA includes 4-bit NormalFloat (NF4)\n",
        "Quantization, which is a quantization scheme\n",
        "optimized for the typical normal distribution of\n",
        "LLM weights. By quantizing based on the\n",
        "quantiles of a normal distribution, NF4 provides\n",
        "better performance than standard 4-bit integer or\n",
        "float quantization. To further reduce memory, the\n",
        "quantization constants are themselves quantized\n",
        "to 8 bits. This second level of quantization\n",
        "saves an additional 0.37 bits per parameter on\n",
        "average. QLORA leverages NVIDIA’s unified\n",
        "memory feature to page optimizer states to CPU\n",
        "RAM when GPU memory is exceeded. avoiding\n",
        "out-of-memory during training. QLORA enables\n",
        "training a 65B parameter LLM on a single 48GB\n",
        "GPU with no degradation compared to full 16-\n",
        "bit finetuning. QLORA works by freezing the\n",
        "4-bit quantized base LLM, then backpropagating\n",
        "\n",
        "\"\"\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_E3lzJq-Epg",
        "outputId": "4480bc56-b0b6-4d92-f356-25176e99f737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " QLORA（Dettmers et al., 2023）は、効率的で効果的なLLMの微調整を提供することを目指して、最適な量子化とメモリ最適化を含んでいます。QLORAには、LLM重みの典型的な正規分布用に最適化された量子化方式である4ビット正規浮動小数点（NF4）量子化が含まれています。正規分布の分位数に基づいて量子化することで、NF4は標準的な4ビット整数または浮動小数点量子化よりも優れた性能を発揮します。メモリをさらに削減するために、量子化定数自体が8ビットに量子化されます。この2番目の量子化レベルにより、平均でパラメータあたり0.37ビットが節約されます。QLORAは、GPUメモリを超えた場合にCPU RAMにオプティマイザの状態をページングするために、NVIDIAの統合メモリ機能を活用しています。これにより、トレーニング中のメモリ不足を回避できます。QLORAにより、完全な16ビット微調整と比較して劣化することなく、単一の48GB GPUで65BパラメータのLLMをトレーニングできます。QLORAは、4ビット量子化されたベースLLMを固定してから、逆伝播させることで動作します。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "P2ZlYM53g8M5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "5b11ada5-d109-4271-db61-860142caab94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' QLORA（Dettmers et al., 2023）は、効率的で効果的なLLMの微調整を提供することを目指して、最適な量子化とメモリ最適化を含んでいます。QLORAには、LLM重みの典型的な正規分布用に最適化された量子化方式である4ビット正規浮動小数点（NF4）量子化が含まれています。正規分布の分位数に基づいて量子化することで、NF4は標準的な4ビット整数または浮動小数点量子化よりも優れた性能を発揮します。メモリをさらに削減するために、量子化定数自体が8ビットに量子化されます。この2番目の量子化レベルにより、平均でパラメータあたり0.37ビットが節約されます。QLORAは、GPUメモリを超えた場合にCPU RAMにオプティマイザの状態をページングするために、NVIDIAの統合メモリ機能を活用しています。これにより、トレーニング中のメモリ不足を回避できます。QLORAにより、完全な16ビット微調整と比較して劣化することなく、単一の48GB GPUで65BパラメータのLLMをトレーニングできます。QLORAは、4ビット量子化されたベースLLMを固定してから、逆伝播させることで動作します。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "shbi7YnghNb0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}